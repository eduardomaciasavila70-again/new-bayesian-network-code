# -*- coding: utf-8 -*-
"""RB_Marzo_2025.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1RI2BgPt3venxKcINtqGIZDAIIQHsVEdm

In this Python program, the goal is to generate a Bayesian network and solve it using PyAgrum libraries. Afterwards, the instructions are coded using our own method in order to compare the results. The results from both methods should be the same since both are exact methods.

It is acknowledged that there are several possible sources of error:

Error in the mathematical formulation, which has been addressed by reviewing the mathematical proofs.

Error during coding, which can be fixed through extensive debugging.

Rounding errors.

This document is composed of several parts:

PART ONE: CREATION OF BAYESIAN NETWORK AND CALCULATION OF PROBABILITY VALUES USING STANDARD METHOD

PART TWO: CREATION OF BAYESIAN NETWORK WITH MERGED NODES

PART THREE: FOR VISUALIZATION ONLY

PART FOUR: SOLVING THE BAYESIAN NETWORK WITH MERGED NODES

PART FIVE SUBROUTINES FOR FINAL CALCULATION (NEW METHOD)

PART SIX CALCULATION (NEW METHOD)

PART SEVEN COMPARISON BETWEEN THE TWO METHODS

PART ONE: CREATION OF BAYESIAN NETWORK AND CALCULATION OF PROBABILITY VALUES USING STANDARD METHOD

Library Installation: PyAgrum
To work with Bayesian Networks in Python, we use the PyAgrum library.
"""

!pip  install pyagrum       # instalacion de libreria
import pyagrum as gum

import pyagrum.lib.notebook as gnb

import numpy as np          # importar  librerias  numericas de python
import matplotlib.pyplot as plt

import pandas as pd

"""Construction of the Bayesian Network
This network is composed of a series of rules known as R0, R1, ..., Rn, where each rule is a vector consisting of 4 elements:

The first element indicates the name of the variable.

The second element indicates the variables that compose it, in case it is a node with merged variables.

The third element indicates the parent nodes.

The last element indicates the probabilities:

If the node has no parents, this element contains the marginal probabilities.

If the node has parents, this element contains the conditional probabilities.

To obtain the number of conditional probabilities in the last element, it is calculated as 2^(ùëõ+ùëö), where:n is the number of parent variables of the node (here it would be ùëõ1+ùëõ2+‚Ä¶, since these parent nodes could also be merged nodes), and m is the number of merged elements composing the node.
"""

# construccion de la red
R0=['FM',[],[],[0.6,0.4]]
R1=['PM',[],[],[0.3,0.7]]
R2=['MTI',[],[],[0.4,0.6]]
R3=['UM',[],[],[0.75,0.25]]
R4=['F',[],['FM','MTI'],[1.0,0.0,0.6,0.40,0.6,0.4,0.15,0.85]]
R5=['B',[],['MTI'],[1,0,0.1,0.9]]
#b=0.6           # 0.03333 <b < 0.7
#d=(0.42-0.6*b)/0.4
#a=0.2           # a < 0.2583
#c=(0.3160-0.24*a-0.36*b-0.24*d)/0.16
a=0.056
b=0.316
c=0.316
d=0.576
R6=['VIH',[],['FM','MTI'],[1-a,a,1-b,b,1-c,c,1-d,d]]
#c=0.5     #0.31< c <0.64333
#d=(0.4825-0.75*c)/0.25
#a=0.1
#b=(0.3195-0.45*c-0.15*d-0.3*a)/0.1
a=0.0070
b=0.2787
c=0.3330
d=0.9307
R7=['SU',[],['MTI','UM'],[1-a,a,1-b,b,1-c,c,1-d,d]]
b=0.8552          # 0.4514 <b < 0.88
a=(0.6160-0.7*b)/0.3
R8=['MM',[],['PM'],[1-a,a,1-b,b]]
a=0.0101
b=0.2357
c=0.2357
d=0.4614
e=0.2357
f=0.4614
g=0.4614
h=0.6870
R9=['MP',[],['F','B','VIH'],[1-a,a,1-b,b,1-c,c,1-d,d,1-e,e,1-f,f,1-g,g,1-h,h]]
# 0.22248a+0.18952b+0.31752c+0.27048d=0.5899
# 0.042a+0.378b+0.058c+0.522d=0.7077
a=0.3775
b=0.6006
c=0.6006
d=0.8237
R10=['MD',[],['F','B'],[1-a,a,1-b,b,1-c,c,1-d,d]]
R11=['FC',[],['F'],[1,0,0.15,0.85]]
a=0.3022
b=0.5264
c=0.5264
d=0.7505
e=0.5264
f=0.7505
g=0.7505
h=0.9747
R12=['ANC',[],['MM','MP','SU'],[1-a,a,1-b,b,1-c,c,1-d,d,1-e,e,1-f,f,1-g,g,1-h,h]]
a=0.1122
b=0.6791
c=0.6791
d=0.9626
e=0.6791
f=0.9626
g=0.9626
h=0.9626
R13=['CR',[],['MM','MD','SU'],[1-a,a,1-b,b,1-c,c,1-d,d,1-e,e,1-f,f,1-g,g,1-h,h]]
R14=['CC',[],['VIH'],[1,0,0.05,0.95]]
Red=[R0,R1,R2,R3,R4,R5,R6,R7,R8,R9,R10,R11,R12,R13,R14]

"""In this part, the network is translated into a format that PyAgrum can understand."""

bn=gum.BayesNet()      # aqui se construye la red bayesiana , definiendo las las variables , se genera un diccionario para tener localizadas las variables
var={}
j=0
for i in Red:
  bn.add(i[0], 2)
  var[i[0]]=j
  j=j+1
print(var)

for i in Red:                  # definicion d elos arcos entre las variables, aqui se ve porque tuve que hacer el diccionario
  ind=len(i[2])
  if ind>0:
    for j in range(0,ind):
      var1=var[i[0]]
      var2=var[i[2][j]]
      bn.addArc(var2,var1)

for i in Red:                     # poner las probabilidades condicionales en la red bayesiana
  ind=len(i[2])
  if ind==0:
    t=[i[3][0],i[3][1]]
    t1=var[i[0]]
    bn.cpt(t1).fillWith(t)


  elif ind==1:
    t1=var[i[0]]
    bn.cpt(t1)[{i[2][0]:0}]=[i[3][0],i[3][1]]
    bn.cpt(t1)[{i[2][0]:1}]=[i[3][2],i[3][3]]


  elif ind==2:
    t1=var[i[0]]
    bn.cpt(t1)[{i[2][0]:0,i[2][1]:0}]=[i[3][0],i[3][1]]
    bn.cpt(t1)[{i[2][0]:0,i[2][1]:1}]=[i[3][2],i[3][3]]
    bn.cpt(t1)[{i[2][0]:1,i[2][1]:0}]=[i[3][4],i[3][5]]
    bn.cpt(t1)[{i[2][0]:1,i[2][1]:1}]=[i[3][6],i[3][7]]


  elif ind==3:
    t1=var[i[0]]
    bn.cpt(t1)[{i[2][0]:0,i[2][1]:0,i[2][2]:0}]=[i[3][0],i[3][1]]
    bn.cpt(t1)[{i[2][0]:0,i[2][1]:0,i[2][2]:1}]=[i[3][2],i[3][3]]
    bn.cpt(t1)[{i[2][0]:0,i[2][1]:1,i[2][2]:0}]=[i[3][4],i[3][5]]
    bn.cpt(t1)[{i[2][0]:0,i[2][1]:1,i[2][2]:1}]=[i[3][6],i[3][7]]
    bn.cpt(t1)[{i[2][0]:1,i[2][1]:0,i[2][2]:0}]=[i[3][8],i[3][9]]
    bn.cpt(t1)[{i[2][0]:1,i[2][1]:0,i[2][2]:1}]=[i[3][10],i[3][11]]
    bn.cpt(t1)[{i[2][0]:1,i[2][1]:1,i[2][2]:0}]=[i[3][12],i[3][13]]
    bn.cpt(t1)[{i[2][0]:1,i[2][1]:1,i[2][2]:1}]=[i[3][14],i[3][15]]

gnb.showBN(bn)

"""LazyPropagation in PyAgrum is an exact inference algorithm based on the Junction Tree algorithm. It computes exact marginal probabilities by propagating beliefs in a junction tree but optimizes computations by delaying some multiplications"""

ie=gum.LazyPropagation(bn)
ie

"""These are probability data taken from the reference:Ben Brahim, A. E. M. Y. B., S.A. Addouche (2019). ‚ÄúBuild a Bayesian Network
from FMECA in the production of Automotive Parts: Diagnosis and Prediction.‚Äù
FAC PapersOnLine, 52-13: 2572‚Äì2577
"""

dict={}
dict['MP']=[0.4,0.7,0.6,0.25,0.4120,0.54,0.3160,0.3195,0.6160,0.2962,0.5899,0.3502,0.5783,0.7648,0.3002]
dict['MTI']=[0.4,0.7,1.00,0.25,0.58,0.90,0.42,0.4825,0.6160,0.4388,0.7077,0.4930,0.6468,0.8316,0.3990]
dict['CR']=[0.4146,0.7892,0.6525,0.2634,0.4639,0.5917,0.3371,0.3768,0.7302,0.3246,0.6951,0.3943,0.6683,1.00,0.3203]
df=pd.DataFrame(dict,index=['FM','PM','MTI','UM','F','B','VIH','SU','MM','MP','MD','FC','ANC','CR','CC'])

"""Marginal probabilities of the Bayesian network calculated by the PyAgrum routines."""

nn=[]
for r in Red:
  var=r[0]
  print(ie.posterior(var))
  pp=ie.posterior(var)
  nn.append(round(pp[1],4))
df['MP BN']=nn
df_nuevo=df[['MP BN']]

df

"""Probabilities of the Bayesian network calculated by the PyAgrum routines when the variable MTI = 1 (Mould Temperature Inadequate)."""

ie.setEvidence({'MTI':1})
ie.makeInference()
nn=[]
for r in Red:
  var=r[0]
  print(ie.posterior(var))
  pp=ie.posterior(var)
  nn.append(round(pp[1],4))
df['MIT BN']=nn
df_nuevo['MIT BN']=nn

"""Probabilities of the Bayesian network calculated by the PyAgrum routines when the variable CR = 1 (Customer Refusal)."""

ie.setEvidence({'CR':1})
ie.makeInference()
nn=[]
for r in Red:
  var=r[0]
  print(ie.posterior(var))
  pp=ie.posterior(var)
  nn.append(round(pp[1],4))
df['CR BN']=nn
df_nuevo['CR BN']=nn

df

df.columns

new_order = ['MP', 'MP BN','MTI', 'MIT BN', 'CR',
       'CR BN']
df = df[new_order]

df

"""Probabilities of the Bayesian network calculated by the PyAgrum routines when the variable CR = 1 (Customer Refusal) and MTI=1 (mould Temperature Inadequate)"""

ie.setEvidence({'MTI':1,'CR':1})
ie.makeInference()
nn=[]
for r in Red:
  var=r[0]
  print(ie.posterior(var))
  ppss=ie.posterior(var)
  nn.append(round(ppss[1],4))
df['MTI CR BN']=nn
df_nuevo['MTI CR BN']=nn

"""Probabilities of the Bayesian network calculated by the PyAgrum routines when the variable CR = 1 (Customer Refusal) , MTI=1 (mould Temperature Inadequate) and PM=1 (placing Material)"""

ie.setEvidence({'MTI':1,'CR':1,'PM':1})
ie.makeInference()
nn=[]
for r in Red:
  var=r[0]
  print(ie.posterior(var))
  ppss=ie.posterior(var)
  nn.append(round(ppss[1],4))
df['MTI CR PM BN']=nn
df_nuevo['MTI CR PM BN']=nn

print(bn)

gnb.showBN(bn)

"""In the problem presented in the article, probabilities were assigned to the nodes to better approximate the results shown in the article. Unfortunately, the article does not provide enough data to deduce the exact values of the conditional probabilities in the nodes. Nonetheless, the best values were sought to closely match these results.

It should be clarified, however, that obtaining the precise values reported in Ibrahim‚Äôs article is not the objective of this work, but rather to demonstrate the agreement between our proposed method and the standard approach for solving Bayesian networks.
"""

df_nuevo

"""PART TWO: CREATION OF BAYESIAN NETWORK WITH MERGED NODES

Nodos: 1er (MTI,FM),UM,PM; 2do. (B,F,VIH,SU),MM, 3er: (MD,MP,SU);4to (CR,ANC),CC,FC
"""

# construccion de la red
R0=['FM',['FM'],[],[0.6,0.4]]
R1=['PM',['PM'],[],[0.3,0.7]]
R2=['MTI',['MTI'],[],[0.4,0.6]]
R3=['UM',['UM'],[],[0.75,0.25]]
R4=['F',['F'],['FM','MTI'],[1.0,0.0,0.6,0.40,0.6,0.4,0.15,0.85]]
R5=['B',['B'],['MTI'],[1,0,0.1,0.9]]
#b=0.6           # 0.03333 <b < 0.7
#d=(0.42-0.6*b)/0.4
#a=0.2           # a < 0.2583
#c=(0.3160-0.24*a-0.36*b-0.24*d)/0.16
a=0.056
b=0.316
c=0.316
d=0.576
R6=['VIH',['VIH'],['FM','MTI'],[1-a,a,1-b,b,1-c,c,1-d,d]]
#c=0.5     #0.31< c <0.64333
#d=(0.4825-0.75*c)/0.25
#a=0.1
#b=(0.3195-0.45*c-0.15*d-0.3*a)/0.1
a=0.0070
b=0.2787
c=0.3330
d=0.9307
R7=['SU',['SU'],['MTI','UM'],[1-a,a,1-b,b,1-c,c,1-d,d]]
R7ad=['SUad',['SUad'],['SU'],[1,0,0,1]]
b=0.8552          # 0.4514 <b < 0.88
a=(0.6160-0.7*b)/0.3
R8=['MM',['MM'],['PM'],[1-a,a,1-b,b]]
a=0.0101
b=0.2357
c=0.2357
d=0.4614
e=0.2357
f=0.4614
g=0.4614
h=0.6870
R9=['MP',['MP'],['F','B','VIH'],[1-a,a,1-b,b,1-c,c,1-d,d,1-e,e,1-f,f,1-g,g,1-h,h]]
# 0.22248a+0.18952b+0.31752c+0.27048d=0.5899
# 0.042a+0.378b+0.058c+0.522d=0.7077
a=0.3775
b=0.6006
c=0.6006
d=0.8237
R10=['MD',['MD'],['F','B'],[1-a,a,1-b,b,1-c,c,1-d,d]]
R11=['FC',['FC'],['F'],[1,0,0.15,0.85]]
a=0.3022
b=0.5264
c=0.5264
d=0.7505
e=0.5264
f=0.7505
g=0.7505
h=0.9747
R12=['ANC',['ANC'],['MM','MP','SUad'],[1-a,a,1-b,b,1-c,c,1-d,d,1-e,e,1-f,f,1-g,g,1-h,h]]
a=0.1122
b=0.6791
c=0.6791
d=0.9626
e=0.6791
f=0.9626
g=0.9626
h=0.9626
R13=['CR',['CR'],['MM','MD','SUad'],[1-a,a,1-b,b,1-c,c,1-d,d,1-e,e,1-f,f,1-g,g,1-h,h]]
R14=['CC',['CC'],['VIH'],[1,0,0.05,0.95]]
Red=[R0,R1,R2,R3,R4,R5,R6,R7,R7ad,R8,R9,R10,R11,R12,R13,R14]

"""Load the itertools library, as it is required in the subroutines."""

import itertools
import pdb
combinaciones = list(itertools.product([0, 1], repeat=2))
combinaciones

"""The following routine is in alpha phase and is used to generate merged nodes."""

def fusion(RN,RG,Redc):       # subrutina que fusiona dos nodos
# RN es el nombre de la nueva variable fusionada
# RG es el grupo de nuevas reglas quese van adicionar
  RGN=[]
  for R in RG:
    RGN.append(R[0])


  RPN=[]
  DPND={}
  DPos={}

  for R in RG:
    #DPND[R[0]]=R[2]
    for elem in R[2]:
      if elem not in RPN:
        RPN.append(elem)
    i=0
    for r in Redc:
      if (r[0]==R[0]):
        DPos[R[0]]=i
      i=i+1

  for R in RG:
    DPND[R[0]]=[]
    for R1 in R[2]:
      for r in Redc:
        if (R1==r[0]):
          nl=len(r[1])
          DPND[R[0]].extend(r[1])





  m=len(RGN)
  RPND={}
  n=0
  for elem in RPN:
    for R in Redc:
      if (elem==R[0]):
        RPND[elem]=R[1]
        n=n+len(R[1])


  comb=list(itertools.product([0, 1], repeat=n+m))
  prob=[1]*(2**(n+m))

  lista=list(RPND.keys())

  #####

  RPNDF = copy.deepcopy(RPN)
  for elem in RPN:
    for r in Redc:
      if (elem==r[0]):
        nl=len(r[1])
        indice = RPNDF.index(r[0])
        RPNDF=RPNDF[:indice] +r[1]+ RPNDF[indice+1:]
        break

  #####

  for co in comb:
    # Convierte la tupla binaria a una cadena y luego a decimal
    ind = int("".join(map(str, co)), 2)
    cm=co[-m:]
    pp=1

    for j in range(0,m):
      nom=RGN[j]
      #### aqui hay un error si se usan nodos fusionados RPN deberia tomar mas indices y solo toma uno, si viene un indice de un nodo despues de uno o mas fusionados
      #### tambien habria error
      valores = [co[RPNDF.index(x)] for x in DPND[nom]]
      ####
      valores.append(cm[j])
      ind1 = int("".join(map(str, valores)), 2)
      pos=DPos[nom]
      ppr=Redc[pos][3][ind1]
      pp=pp*ppr
    #valores = [com[RPN.index(x)] for x in RPND[][1]]
    #for r  in RGN:

    prob[ind]=pp



  ###########



##### esto por modificar, pero como

  # Generacion de nueva regla
  RNN=[RN,RGN,RPN,prob]

  # modificacion de la red

  ultimo_indice = max(Redc.index(x) for x in RG)

  Redc.insert(ultimo_indice + 1, RNN)
  for elem in RG:
    Redc.remove(elem)
  indice=ultimo_indice+1-len(RG)


  ###  modificacion mas d ela red
  for i, R in enumerate(Redc):
    if i != indice:
      existe = any(elem in R[2] for elem in RGN)
      if existe:
        R1 = [elem for elem in R[2] if elem not in RGN]
        RS1=copy.deepcopy(R1)
        RS1.append(RGN)
        RS1.append(R[1])
        R2=copy.deepcopy(R[2])
        R2.append((R[1]))
        RS1 = [elem for sublista in RS1 for elem in (sublista if isinstance(sublista, list) else [sublista])]
        R2 = [elem for sublista in R2 for elem in (sublista if isinstance(sublista, list) else [sublista])]

        R1.append(RN)
        R[2]=R1
        nn=len(RS1)
        comb=list(itertools.product([0, 1], repeat=nn))
        nt=2**nn
        RP=[0] * nt

        for co in comb:
          # Convierte la tupla binaria a una cadena y luego a decimal
          ind = int("".join(map(str, co)), 2)
          valores = [co[RS1.index(x)] for x in R2]
          ind1 = int("".join(map(str, valores)), 2)
          RP[ind]=R[3][ind1]

        R[3]=RP

  #####


  return RNN,Redc

import copy
Redm = copy.deepcopy(Red)

"""The following instructions show how merged nodes are generated. It is important to note that not only are nodes with internally merged nodes created, but it is also necessary to generate the list of conditional probabilities for the merged node (this is done by the previously shown fusion subroutine)."""

R02,Red1=fusion('FM-MTI',[R0,R2],Redm)

R02

Red1m = copy.deepcopy(Red1)

R03,Red2=fusion('B-F-VIH-SU', [Red1[4],Red1[3],Red1[5],Red1[6]],Red1m)

print(R03[0])
print(R03[1])
print(R03[2])

Red2m = copy.deepcopy(Red2)

R04,Red3=fusion('MD-MP-SUad', [Red2[7],Red2[6],Red2[4]],Red2m)

print(R04[0])
print(R04[1])
print(R04[2])

Red3m = copy.deepcopy(Red3)

R05,Red4=fusion('CR-ANC', [Red3[8],Red3[7]],Red3m)

print(R05[0])
print(R05[1])
print(R05[2])

ind=8
Red4[ind][0],Red4[ind][1],Red4[ind][2]

"""PART THREE: FOR VISUALIZATION ONLY

No subroutines were created to visualize the Bayesian network; in this case, other PyAgrum subroutines are used to generate the Bayesian network and display how it looks.
"""

bnf=gum.BayesNet()      # aqui se construye la red bayesiana , definiendo las las variables , se genera un diccionario para tener localizadas las variables
bnf.add('MTI, FM', 4)
bnf.add('UM', 2)
bnf.add('PM', 2)
bnf.add('B, F, VIH, SU', 16)
bnf.add('MM', 2)
bnf.add('MD, MP, SUad', 8)
bnf.add('CR, ANC', 4)
bnf.add('CC',2)
bnf.add('FC', 2)

bnf.addArc('MTI, FM','B, F, VIH, SU')
bnf.addArc('UM','B, F, VIH, SU')
bnf.addArc('PM','MM')
bnf.addArc('B, F, VIH, SU','MD, MP, SUad')
bnf.addArc('B, F, VIH, SU','CC')
bnf.addArc('B, F, VIH, SU','FC')
bnf.addArc('MM','CR, ANC')
bnf.addArc('MD, MP, SUad','CR, ANC')

gnb.showBN(bnf)

"""PART FOUR: SOLVING THE BAYESIAN NETWORK WITH MERGED NODES USING THE NEW METHOD

CALCULATION OF MERGED PROBABILITIES

In this section, the subroutines developed using the new evidence propagation method are presented. These subroutines are used to calculate the probabilities of the nodes that are part of the Bayesian network.

Subroutine to generate an encoded list of binary numbers
"""

# generacion de codificacion
def codigo(nn):
  m=2**nn
  mm=list(range(m))
  mb = [bin(num)[2:].zfill(nn) for num in mm]
  return mb

"""Calculation of Marginal Probabilities in the bayesian network"""

# calculo de probabilidades marginales
def probabilidad_marginal(Red):
  pm={}  #para almacenar los valores de probabilidades marginales

  for Rn in Red:
    # asignacion de elementos padres en la regla
    np=len(Rn[2])
    val=Rn[0]
    if (np==0):
      pm[val]=Rn[3]
      continue


    # asignacion de probablidades marginales que conforman la regla
    nelem=len(Rn[1])
    mb =codigo(nelem)

    # asignacion de la posicion de los padres del nodo en la red
    indP=[]
    for i, r in enumerate(Rn[2]):
      for j,R in enumerate(Red):
        if (r==R[0]):
          indP.append(j)
          break
      #print(i)
      #print(r)
      #print(indP[i])
      #print(Red[indP[i]][0])


    pad={}
    nsp=0
    for i, r in enumerate(Rn[2]):
      nelemp=len(Red[indP[i]][1])
      nsp=nsp+nelemp
      pad[r]=nsp
      #print(r)
      #print(Red[indP[i]][1])
      #print(nelemp)
      #print(nsp)


    mpp=codigo(nsp)
 # calculo de probabilidades
    PP=[]
    for am in  mb:
      sum=0
      for amp in mpp:

        ampr=amp+am
        dampr = int(ampr, 2)
        pos=[]
        npos=0
        pp=1

        for i,r in enumerate(Rn[2]):
          nsp=pad[r]
          dam=int(ampr[npos:nsp],2)
          npos=nsp
          pp=pp*pm[r][dam]

        sum=sum+pp*Rn[3][dampr]

      PP.append(sum)

    pm[val]=PP


  return pm

Red5=[Red4[0],Red4[1],Red4[2],Red4[3],Red4[4],Red4[5],Red4[6],Red4[7],Red4[8]]

pmm=probabilidad_marginal(Red5)

for p in pmm:
  print(p)

def variable_probability(VAR, var):
    """
    Calcula la probabilidad de que la variable 'var' (por nombre o √≠ndice)
    tome el valor 1.

    VAR: lista de dos elementos.
         VAR[0] es la lista de nombres de variables.
         VAR[1] es la lista de probabilidades para cada combinaci√≥n de valores.
         Se asume que hay 2^n combinaciones para n variables.
    var: puede ser el nombre de la variable (str) o su √≠ndice (int).
    """
    variables = VAR[0]
    probs = VAR[1]
    n = len(variables)

    # Determinamos el √≠ndice de la variable si se pas√≥ como nombre
    if isinstance(var, str):
        try:
            i = variables.index(var)
        except ValueError:
            raise ValueError(f"La variable {var} no se encuentra en la lista de variables.")
    elif isinstance(var, int):
        if 0 <= var < n:
            i = var
        else:
            raise ValueError(f"El √≠ndice debe estar entre 0 y {n-1}")
    else:
        raise ValueError("El par√°metro 'var' debe ser un nombre (str) o un √≠ndice (int).")

    prob_sum = 0
    # Recorremos cada combinaci√≥n representada por su √≠ndice j
    for j, p in enumerate(probs):
        # Convertimos j en binario y revisamos la posici√≥n correspondiente a la variable.
        # La variable en posici√≥n i corresponde al bit en la posici√≥n (n - 1 - i) de j.
        if j & (1 << (n - 1 - i)):
            prob_sum += p
    return prob_sum

dir={}
VAR=[['PM'],pmm['PM']]
dir['PM']=variable_probability(VAR,'PM')
VAR=[['FM','MTI'],pmm['FM-MTI']]
dir['FM']=variable_probability(VAR,'FM')
dir['MTI']=variable_probability(VAR,'MTI')
VAR=[['UM'],pmm['UM']]
dir['UM']=variable_probability(VAR,'UM')
VAR=[['B','F','VIH','SU'],pmm['B-F-VIH-SU']]
dir['B']=variable_probability(VAR,'B')
dir['F']=variable_probability(VAR,'F')
dir['VIH']=variable_probability(VAR,'VIH')
dir['SU']=variable_probability(VAR,'SU')
VAR=[['MM'],pmm['MM']]
dir['MM']=variable_probability(VAR,'MM')
VAR=[['MD','MP','SUad'],pmm['MD-MP-SUad']]
dir['MD']=variable_probability(VAR,'MD')
dir['MP']=variable_probability(VAR,'MP')
VAR=[['FC'],pmm['FC']]
dir['FC']=variable_probability(VAR,'FC')
VAR=[['CR','ANC'],pmm['CR-ANC']]
dir['CR']=variable_probability(VAR,'CR')
dir['ANC']=variable_probability(VAR,'ANC')
VAR=[['CC'],pmm['CC']]
dir['CC']=variable_probability(VAR,'CC')

dir

df['NM']=dir

"""It is shown that marginal probabilities can be obtained by comparing the NM column with the MP BN column (standard evidence propagation method)."""

df

import itertools
import numpy as np
import pdb

"""Subroutine for calculation of evidence propagation in the bayesian network

# **PART FIVE SUBROUTINES FOR FINAL CALCULATION (NEW METHOD)**

**Evidence Propagation Subroutines**

Subroutine to obtain a list of binary numbers for encoding purposes
"""

# obtener una lista de codigos de numeros binarios
 def codigo(nn):
  mm=2**nn
  mb=[bin(num)[2:].zfill(nn) for num in range(mm)]
  return mb

codigo(3)

"""Obtain a list of codes of intermediate binary numbers, where:

nn is the number of data points,

np is the position of the data to consider (position ranges from 0 to nn-1),

val is the value 0 or 1.
"""

# obtener una lista de codigos de numeros intermedios binarios
def codigoInt(nn,np,val):

  # nn es un numero de datos, np es la posicion de dato a considerar (la posicion va de 0 a nn-1), val es el valor 0 o 1
  if (np==0):
    bb=codigo(nn-1)
    lista=[str(val)+b for b in bb]
  elif (np==nn-1):
    bb=codigo(nn-1)
    lista=[b+str(val) for b in bb]
  else:
    bb1=codigo(np)
    bb2=codigo(nn-np-1)
    lista=[]
    for b1 in bb1:
      for b2 in bb2:
        lista.append(b1+str(val)+b2)

  return lista

codigoInt(4,1,1)

"""Convert from binary list to decimal (important to locate the position in the list of conditional probabilities or probability factors).
Given a binary number, it is converted to decimal indicating the position.
"""

# cambiar de lista binaria a decimal
def codigo_d(bb):
  mb=[int(b,2) for b in bb]
  return mb

bb=codigoInt(4,1,1)
codigo_d(bb)

"""Function to display the names of the variables in the Bayesian network"""

# funcion para mostrar los nombres de las variables
def nomRed(Redc):
  nom=[]
  for r in Redc:
    nom.append(r[0])
  return nom

lista=nomRed(Red5)
lista

"""Calculation of the node probability based on its merged nodes

pp is a list composed of sublists where the first element is the name of the merged node,

nom is the name of the nodes, and val is the value 0 or 1
"""

# calculo de probabilidad d enodo a partir de sus nodos fusionados
def prob(pp,nom,val):
  # pp es una lista compuesta de sublistas donde el primero es el nombre del nodo fusionado, nom es uno el nombre de los nodos y val es el valor  0 o 1

  for i,r in enumerate(pp):
    if (nom in r[1]):
      indr=i
      break

  n=len(pp[indr][1])
  if n==1:
    valp=pp[indr][2][val]
  else:
    suma=0
    np=pp[indr][1].index(nom)
    bb=codigoInt(n,np,val)
    bd=codigo_d(bb)
    for d in bd:
      suma=suma+pp[indr][2][d]
    valp=suma

  return valp

from itertools import product
import math

"""Determine probability from parent nodes

Redc is the network to be tested,

ind is the index of the variable in the network to calculate,

pp is the list of probabilities

this is FORWARD PROPAGATION EVIDENCE
"""

# determinar probabilidad a partir de nodos padres
def prob_p(Redc, ind, pp):
  # Redc es la red a probar, ind es elnumero de la variable en la red a calcular , pp es la lista de probabilidades
  res=[]
  res.append(Redc[ind][0])
  res.append(Redc[ind][1])
  nn=len(Redc[ind][2])


  if (nn==0):
    res.append(Redc[ind][3])
  else:
    var=nomRed(Redc)
    padres=Redc[ind][2]
    mp=len(padres)
    indi=[var.index(x) for x in padres]
    fus=[Redc[indd][1] for indd in indi]
    mm=len(Redc[ind][1])
    binf=codigo(mm)


    bfath=[]
    bfathp=[]
    for j in range(mp):
      jj=indi[j]
      mp1=len(pp[jj][1])
      bb=codigo(mp1)
      bfath.append(bb)
      bfathp.append(pp[jj][2])


    # Combinaciones de texto
    combinaciones_texto = list(product(*bfath))

    # Combinaciones de n√∫meros
    combinaciones_numeros = list(product(*bfathp))


    # Ahora combinamos todo:
    bfatht = [''.join(elem) for elem in combinaciones_texto]
    bfatht_numerico = [math.prod(numeros) for numeros in combinaciones_numeros]


    res.append([])

    for i,bb in enumerate(binf):
      # este falta de resolver
      lista=[b+bb for b in bfatht]
      lista_dec=codigo_d(lista)
      numerico=[Redc[ind][3][u] for u in lista_dec]
      resultado = [x * y for x, y in zip(numerico, bfatht_numerico)]
      suma=sum(resultado)
      res[2].append(suma)






  return res

"""Determine marginal probability. the calculation of marginal probability is composed by forward propagation"""

# determinar probabilidad marginal
def probabilidad_marginal(Redc):
  pp=[]
  for ind,r in enumerate(Redc):
    res=prob_p(Redc, ind, pp)
    pp.append(res)

  return pp

lista=nomRed(Red5)
lista

"""Calculation of marginal probabilities in the bayesian network"""

pp=[]
pp=probabilidad_marginal(Red5)
dir={}
for p in pp:
  for pf in p[1]:
    nom=pf
    dir[nom]=round(prob(pp,nom,1),4)
dir

df['NM1']=dir
df

df_nuevo['MP NM']=dir
df_nuevo['MP NM']

"""**Internal propagation in nodes**

Redc is the network to be tested,

ind is the index of the variable in the network to calculate,

pp is the list of probabilities,

var would be the variable of the nodes to consider,

val would be the value to take.
"""

# propagacion interna en nodos
def propagacion_interna(Redc,ind,var,val,pp):
  # Redc es la red a probar, ind es elnumero de la variable en la red a calcular , pp es la lista de probabilidades
  # var seria la variable de los nodos a considerar, val seria el valor a tomar

  p=[]
  if (len(Redc[ind][1])==1):
    p=[1-val,val]

  else:
    r=Redc[ind][1]
    np=r.index(var)
    nn=len(r)
    bb=codigoInt(nn,np,val)
    indices=codigo_d(bb)


    nt=len(pp[ind][2])
    pr=nt*[0]


    for i in indices:
      pr[i] = pp[ind][2][i]

    suma = sum(pr)
    pr = [x / suma for x in pr]
    p=pr


  return p

"""**FORWARD PROPAGATION **

Determine forward evidence propagation
"""

# determinar la propagacion de evidencia hacia adelante
def prob_hacia_adelante(Redc, ind, pp):
  res=prob_p(Redc, ind, pp)

  return res

import copy

"""**LATERAL PROPAGATION **

Determine Lateral evidence propagation
Redc is the network, ind is the index number of the child, pp is the list of probabilities, var is the evidence propagation variable which must be one of the child's parents.
var is a merged node; define the lateral nodes.
"""

# determinar la propagacion de evidencia lateral
def prob_lateral(Redc, ind, pp, var):
  # Redc es la red , ind es el numero de indice del hijo, pp es lista de probabilidades, var es variable de propagacion de evidencia debe ser uno de los padres del hijo
  # var es un nodo fusionado, definir los laterales
  lista=nomRed(Redc)   # poner la lista de posiciones de la variable
  fusion=Redc[ind][1]  # nodos fusionados
  n=len(fusion)
  bhij=codigo(n)         # lista de codigos binarios
  padres=Redc[ind][2]  # nodos padres
  resp={}
  for r in padres:
    res=[]
    if (r!=var):
      indr=lista.index(r)          # posicion de nodo en la red
      nn=len(Redc[indr][1])
      bbr=codigo(nn)               # lista d ecodigo binario en determinado nodo padre
      ppr=pp[indr][2]              # lista de probabilidades, mismo tama√±o que el de codigo

      for i,bbi in enumerate(bbr):
        pb=[]
        pf=[]
        nnt=0
        for rr in padres:
          if (rr==r):
            pb.append(bbi)
            pf.append(ppr[i])
            indv=lista.index(rr)
            nn=len(Redc[indv][1])
            nnt=nnt+nn
          else:
            indv=lista.index(rr)
            nn=len(Redc[indv][1])
            nnt=nnt+nn
            bb=codigo(nn)
            pb.append(bb)
            pf.append(pp[indv][2])


        # Combinaciones de texto
        pb2 = [ [x] if isinstance(x, str) else x for x in pb ]
        combinaciones_texto = [''.join(tupla) for tupla in product(*pb2)]
        # Combinaciones de n√∫meros
        pf2 = [ [x] if isinstance(x, float) else x for x in pf ]
        combinaciones_prob = list(product(*pf2))
        combinaciones_numeros = [float(np.prod(comb)) for comb in combinaciones_prob]

        # Ahora combinamos todo:
        bfatht = combinaciones_texto
        bfatht_numerico = combinaciones_numeros

        # hasta aqui vamos
        lista1=[]
        for bb in bfatht:
          suma=0

          for bb1 in bhij:
            num1=int(bb+bb1,2)
            suma=suma+Redc[ind][3][num1]
          lista1.append(suma)
        resultado = [a * b for a, b in zip(lista1, bfatht_numerico)]
        suma=sum(resultado)
        res.append(suma)

      resp[r]=res

  return resp

"""Determine lateral evidence propagation, the coefficients (probability factors).
Redc is the network, ind is the index number of the child, pp is the list of probabilities, ppv is the previous list of probabilities.
Remember that for the propagation parent variable, it will have the same value in both pp and ppv.
You need to specify which variable should not be updated in the coefficient calculation ‚Äî that one goes in var.
"""

# determinar la propagacion de evidencia lateral, los coeficientes
def prob_lateral_coef(Redc, ind, pp, ppv, var):
  # Redc es la red , ind es el numero de indice del hijo, pp es lista de probabilidades, ppv es la anterior lista de probabilidades
  # recordar que para la variable padre de propagacion tendra el mismo valor enpp y en ppv
  # tienes que especificar cual variable no va en la actualizacion del coeficiente y esa va en var
  lista=nomRed(Redc)   # poner la lista de posiciones de la variable
  padres=Redc[ind][2]  # nodos padres
  pb=[]
  ppa=[]
  ppn=[]
  pf=[]
  for r in padres:
    indv=lista.index(r)
    nn=len(Redc[indv][1])
    bb=codigo(nn)
    pb.append(bb)
    if (r!=var):
      ppa.append(ppv[indv][2])
      ppn.append(pp[indv][2])
    else:
      ppa.append(len(ppv[indv][2])*[1])
      ppn.append(len(pp[indv][2])*[1])



  # Combinaciones de texto
  combinaciones_texto = list(product(*pb))
  bfatht = [''.join(elem) for elem in combinaciones_texto]
  # Combinaciones de n√∫meros
  combinaciones_numerosv = list(product(*ppa))
  bfatht_numerico_a = [math.prod(numeros) for numeros in combinaciones_numerosv]
  # Combinaciones de n√∫meros
  combinaciones_numerosn = list(product(*ppn))
  bfatht_numerico_n = [math.prod(numeros) for numeros in combinaciones_numerosn]
  # Ahora combinamos todo:


  nfus=len(Redc[ind][1])
  bb=codigo(nfus)
  coef=copy.deepcopy(Redc[ind][3])
  for bp in bfatht:
    num1=int(bp,2)
    for bh in bb:
      num2=int(bp+bh,2)
      if (bfatht_numerico_n[num1]==0):
        coef[num2]=Redc[ind][3][num2]
      else:
        coef[num2]=Redc[ind][3][num2]*bfatht_numerico_a [num1]/bfatht_numerico_n[num1]


  return coef

"""Determine backward evidence propagation coefficients (probability factors).
Redc is the network, ind is the index number of the child, pp is the list of probabilities, ppv is the previous list of probabilities.
"""

# determinar la propagacion de evidencia hacia atras coeficientes
def prob_hacia_atras_coef(Redc, ind, pp, ppv):
  # Redc es la red , ind es el numero de indice del hijo, pp es lista de probabilidades, ppv es la anterior lista de probabilidades
  lista=nomRed(Redc)   # poner la lista de posiciones de la variable
  padres=Redc[ind][2]  # nodos padres
  pb=[]
  ppa=[]
  ppn=[]
  pf=[]
  for r in padres:
    indv=lista.index(r)
    nn=len(Redc[indv][1])
    bb=codigo(nn)
    pb.append(bb)
    ppa.append(ppv[indv][2])
    ppn.append(pp[indv][2])


  # Combinaciones de texto
  combinaciones_texto = list(product(*pb))
  bfatht = [''.join(elem) for elem in combinaciones_texto]
  # Combinaciones de n√∫meros
  combinaciones_numerosv = list(product(*ppa))
  bfatht_numerico_a = [math.prod(numeros) for numeros in combinaciones_numerosv]
  # Combinaciones de n√∫meros
  combinaciones_numerosn = list(product(*ppn))
  bfatht_numerico_n = [math.prod(numeros) for numeros in combinaciones_numerosn]
  # Ahora combinamos todo:


  nfus=len(Redc[ind][1])
  bb=codigo(nfus)
  coef=copy.deepcopy(Redc[ind][3])
  for bp in bfatht:
    num1=int(bp,2)
    for bh in bb:
      num2=int(bp+bh,2)
      num3=int(bh,2)
      if (bfatht_numerico_n[num1]==0) or (ppv[ind][2][num3]==0):
        coef[num2]=Redc[ind][3][num2]
      else:
        coef[num2]=Redc[ind][3][num2]*bfatht_numerico_a [num1]/bfatht_numerico_n[num1]*pp[ind][2][num3]/ppv[ind][2][num3]


  return coef

"""Determine **BACKWARD EVIDENCE PROPAGATION**.
Redc is the network, ind is the index number of the child, pp is the list of probabilities, ppv is the previous list of probabilities.
"""

# determinar la propagacion de evidencia hacia atras
def prob_hacia_atras(Redc, ind, ppv,pp):
  # Redc es la red , ind es el numero de indice del hijo, pp es lista de probabilidades, ppv es la anterior lista de probabilidades
  lista=nomRed(Redc)   # poner la lista de posiciones de la variable
  fus=Redc[ind][1]
  nfus=len(fus)
  bbi=codigo(nfus)
  padres=Redc[ind][2]  # nodos padres
  res={}
  for r in padres:
    indvr=lista.index(r)
    fus=Redc[indvr][1]
    nfus=len(fus)
    bb=codigo(nfus)
    pb=[]
    pf=[]
    res[r]=[]
    for b in bb:
      pb=[]
      pf=[]
      numb=int(b,2)
      for rr in padres:
        if (rr==r):
          pb.append(b)
          pf.append([1])
        else:
          indv=lista.index(rr)
          nn=len(Redc[indv][1])
          bb=codigo(nn)
          pb.append(bb)
          pf.append(pp[indv][2])
      # Combinaciones de texto
      pb2 = [ [x] if isinstance(x, str) else x for x in pb ]
      combinaciones_texto = [''.join(tupla) for tupla in product(*pb2)]
      bfatht = combinaciones_texto
      # Combinaciones de n√∫meros
      pf2 = [ [x] if isinstance(x, float) else x for x in pf ]
      combinaciones_prob = list(product(*pf2))
      combinaciones_numeros = [float(np.prod(comb)) for comb in combinaciones_prob]
      bfatht_numerico=combinaciones_numeros
      # Ahora combinamos todo:


      # me estoy haciendo bolas
      resa=[]
      for bi in bbi:
        num1=int(bi,2)
        prodc=[]
        for jf,bf in enumerate(bfatht):
          num=int(bf+bi,2)
          Redd=copy.deepcopy(Redc[ind][3][num])
          prodc.append(Redd*bfatht_numerico[jf])
        suma=sum(prodc)
        resa.append(suma)

      nni=len(bbi)
      suma=0
      for i in range(nni):
        if (ppv[ind][2][i]!=0):
          suma=suma+resa[i]*pp[ind][2][i]/ppv[ind][2][i]

      res[r].append(suma*ppv[indvr][2][numb])

  return res

ppv=copy.deepcopy(pp)

df

gnb.showBN(bnf)

lista=nomRed(Red5)
lista

"""**PART SIX  CALCULATION (NEW METHOD)**"""

Red6m=copy.deepcopy(Red5)
pp6=copy.deepcopy(pp)

"""Calculation of probabilities in the Bayesian network using the new method when MTI = 1 (evidence).
A routine could have been created to automatically calculate the processing path in the network, but it was preferred to leave it in a less automated way to show all the steps. Probabilities are calculated, and, if necessary, probability factors are updated when changes occur.
"""

# este fue MTI=1
dir={}
ppnn=copy.deepcopy(pp)
# los que no fueron calculados
dir['PM']=round(prob(pp,'PM',1),4)
dir['UM']=round(prob(pp,'UM',1),4)
dir['MM']=round(prob(pp,'MM',1),4)
###

ppnn[1][2]=propagacion_interna(Red5,1,'MTI',1,pp)
#print(round(prob(ppnn,'FM',1),4))
#print(round(prob(ppnn,'MTI',1),4))
dir['FM']=round(prob(ppnn,'FM',1),4)
dir['MTI']=round(prob(ppnn,'MTI',1),4)
res=prob_hacia_adelante(Red5, 3, ppnn)
ppnn[3][2]=copy.deepcopy(res[2])
#print(round(prob(ppnn,'B',1),4))
#print(round(prob(ppnn,'F',1),4))
#print(round(prob(ppnn,'VIH',1),4))
#print(round(prob(ppnn,'SU',1),4))
dir['B']=round(prob(ppnn,'B',1),4)
dir['F']=round(prob(ppnn,'F',1),4)
dir['VIH']=round(prob(ppnn,'VIH',1),4)
dir['SU']=round(prob(ppnn,'SU',1),4)
res=prob_hacia_adelante(Red5, 5, ppnn)
ppnn[5][2]=copy.deepcopy(res[2])
#print(round(prob(ppnn,'MD',1),4))
#print(round(prob(ppnn,'MP',1),4))
print(round(prob(ppnn,'SUad',1),4))
dir['MD']=round(prob(ppnn,'MD',1),4)
dir['MP']=round(prob(ppnn,'MP',1),4)
res=prob_hacia_adelante(Red5, 6, ppnn)
ppnn[6][2]=copy.deepcopy(res[2])
#print(round(prob(ppnn,'FC',1),4))
dir['FC']=round(prob(ppnn,'FC',1),4)
res=prob_hacia_adelante(Red5, 8, ppnn)
ppnn[8][2]=copy.deepcopy(res[2])
#print(round(prob(ppnn,'CC',1),4))
dir['CC']=round(prob(ppnn,'FM',1),4)
res=prob_hacia_adelante(Red5, 7, ppnn)
ppnn[7][2]=copy.deepcopy(res[2])
#print(round(prob(ppnn,'CR',1),4))
#print(round(prob(ppnn,'ANC',1),4))
dir['CR']=round(prob(ppnn,'CR',1),4)
dir['ANC']=round(prob(ppnn,'ANC',1),4)


#checar que no se alteren las probabilidades de los otros
print(round(prob(pp,'UM',1),4))
print(round(prob(pp,'MM',1),4))
print(round(prob(pp,'PM',1),4))
res=prob_lateral(Red5, 3, ppnn, 'FM-MTI')
ppnn[2][2]=copy.deepcopy(res['UM'])
print(round(prob(ppnn,'UM',1),4))
res=prob_lateral(Red5, 7, ppnn, 'MD-MP-SUad')
ppnn[4][2]=copy.deepcopy(res['MM'])
print(round(prob(ppnn,'MM',1),4))
res=prob_hacia_atras(Red5, 4, pp,ppnn)   # hubo cambio , error checar
ppnn[0][2]=res['PM']
print(round(prob(ppnn,'PM',1),4))

# checar coeficientes
print(Red5[3][3][0:4])
coef=prob_lateral_coef(Red5, 3,ppnn, pp,'FM-MTI')
print(coef[0:4])
print(Red5[7][3][0:4])
coef=prob_lateral_coef(Red5, 7,ppnn, pp,'MD-MP-SUad')
print(coef[0:4])
print(Red5[4][3])
coef=prob_hacia_atras_coef(Red5, 4, ppnn, pp)
print(coef)

df['MIT NM']=dir
df

df_nuevo['MIT NM']=dir
df_nuevo[['MP NM','MIT NM']]

lista

gnb.showBN(bnf)

"""Calculation of probabilities in the Bayesian network using the new method when CR = 1 (evidence). A routine could have been created to automatically calculate the processing path in the network, but it was preferred to leave it in a less automated way to show all the steps. Probabilities are calculated, and, if necessary, probability factors are updated when changes occur."""

# este fue CR=1,
Red6=copy.deepcopy(Red6m)

dir={}
ppn=copy.deepcopy(pp6)
ppn[7][2]=propagacion_interna(Red6,7,'CR',1,pp6)
print(round(prob(ppn,'CR',1),4))
print(round(prob(ppn,'ANC',1),4))
dir['CR']=round(prob(ppn,'CR',1),4)
dir['ANC']=round(prob(ppn,'ANC',1),4)
res=prob_hacia_atras(Red6, 7, pp6,ppn)   # lo pusiste al reves
ppn[4][2]=res['MM']
print(round(prob(ppn,'MM',1),4))
dir['MM']=round(prob(ppn,'MM',1),4)
ppn[5][2]=res['MD-MP-SUad']
print(round(prob(ppn,'MD',1),4))
print(round(prob(ppn,'MP',1),4))
print(round(prob(ppn,'SUad',1),4))
dir['MD']=round(prob(ppn,'MD',1),4)
dir['MP']=round(prob(ppn,'MP',1),4)
res=prob_hacia_atras(Red6, 4, pp,ppn)
ppn[0][2]=res['PM']
print(round(prob(ppn,'PM',1),4))
dir['PM']=round(prob(ppn,'PM',1),4)
res=prob_hacia_atras(Red6, 5, pp,ppn)
ppn[3][2]=res['B-F-VIH-SU']
print(round(prob(ppn,'B',1),4))
print(round(prob(ppn,'F',1),4))
print(round(prob(ppn,'VIH',1),4))
print(round(prob(ppn,'SU',1),4))
dir['B']=round(prob(ppn,'B',1),4)
dir['F']=round(prob(ppn,'F',1),4)
dir['SU']=round(prob(ppn,'SU',1),4)
dir['VIH']=round(prob(ppn,'VIH',1),4)
res=prob_hacia_atras(Red6, 3, pp,ppn)
ppn[1][2]=res['FM-MTI']
print(round(prob(ppn,'FM',1),4))
print(round(prob(ppn,'MTI',1),4))
dir['FM']=round(prob(ppn,'FM',1),4)
dir['MTI']=round(prob(ppn,'MTI',1),4)
ppn[2][2]=res['UM']
print(round(prob(ppn,'UM',1),4))
dir['UM']=round(prob(ppn,'UM',1),4)
res=prob_hacia_adelante(Red6, 6, ppn)
ppn[6][2]=res[2]
print(round(prob(ppn,'FC',1),4))
dir['FC']=round(prob(ppn,'FC',1),4)
res=prob_hacia_adelante(Red6, 8, ppn)
ppn[8][2]=res[2]
print(round(prob(ppn,'CC',1),4))
dir['CC']=round(prob(ppn,'CC',1),4)

coef=prob_hacia_atras_coef(Red6, 7, ppn, pp6)
Red6[7][3]=copy.deepcopy(coef)
coef=prob_hacia_atras_coef(Red6, 4, ppn, pp6)
Red6[4][3]=copy.deepcopy(coef)
coef=prob_hacia_atras_coef(Red6, 5, ppn, pp6)
Red6[5][3]=copy.deepcopy(coef)
coef=prob_hacia_atras_coef(Red6, 3, ppn, pp6)
Red6[3][3]=copy.deepcopy(coef)

df['CR NM']=dir
df

df_nuevo['CR NM']=dir
df_nuevo[['MP NM','CR NM']]

gnb.showBN(bnf)

lista

"""Calculation of probabilities in the Bayesian network using the new method when CR = 1 (evidence) and MTI = 1. These calculations were first performed based on the probabilities when MTI = 1 (which had already been previously calculated), and then the new evidence CR = 1 was introduced.

A routine could have been created to automatically calculate the processing path in the network, but it was preferred to leave it in a less automated way to show all the steps. Probabilities are calculated, and, if necessary, probability factors are updated when changes occur.
"""

# propagacion de CR=1 seguido con MTI =1
##
print(Red6[4][3])
print(Red6[4][3][0]+Red6[4][3][1])
print(Red6[4][3][2]+Red6[4][3][3])
##
dir={}
ppnn=copy.deepcopy(ppn)
ppnn[1][2]=propagacion_interna(Red6,1,'MTI',1,ppn)
print(round(prob(ppnn,'MTI',1),4))
print(round(prob(ppnn,'FM',1),4))
dir['MTI']=round(prob(ppnn,'MTI',1),4)
dir['FM']=round(prob(ppnn,'FM',1),4)
res=prob_hacia_adelante(Red6, 3, ppnn)
ppnn[3][2]=copy.deepcopy(res[2])
print(round(prob(ppnn,'B',1),4))
print(round(prob(ppnn,'F',1),4))
print(round(prob(ppnn,'VIH',1),4))
print(round(prob(ppnn,'SU',1),4))
dir['B']=round(prob(ppnn,'B',1),4)
dir['F']=round(prob(ppnn,'F',1),4)
dir['VIH']=round(prob(ppnn,'VIH',1),4)
dir['SU']=round(prob(ppnn,'SU',1),4)
res=prob_lateral(Red6, 3, ppnn, 'FM-MTI')
ppnn[2][2]=copy.deepcopy(res['UM'])
print(round(prob(ppnn,'UM',1),4))
dir['UM']=round(prob(ppnn,'UM',1),4)
res=prob_hacia_adelante(Red6, 6, ppnn)
ppnn[6][2]=copy.deepcopy(res[2])
print(round(prob(ppnn,'FC',1),4))
dir['FC']=round(prob(ppnn,'FC',1),4)
res=prob_hacia_adelante(Red6, 8, ppnn)
ppnn[8][2]=copy.deepcopy(res[2])
print(round(prob(ppnn,'CC',1),4))
dir['CC']=round(prob(ppnn,'CC',1),4)
res=prob_hacia_adelante(Red6, 5, ppnn)
ppnn[5][2]=copy.deepcopy(res[2])
print(round(prob(ppnn,'MD',1),4))
print(round(prob(ppnn,'MP',1),4))
print(round(prob(ppnn,'SUad',1),4))
dir['MD']=round(prob(ppnn,'MD',1),4)
dir['MP']=round(prob(ppnn,'MP',1),4)
res=prob_hacia_adelante(Red6, 7, ppnn)
ppnn[7][2]=copy.deepcopy(res[2])
print(round(prob(ppnn,'CR',1),4))
print(round(prob(ppnn,'ANC',1),4))
dir['CR']=round(prob(ppnn,'CR',1),4)
dir['ANC']=round(prob(ppnn,'ANC',1),4)
res=prob_lateral(Red6, 7, ppnn, 'MD-MP-SUad')
ppnn[4][2]=copy.deepcopy(res['MM'])
print(round(prob(ppnn,'MM',1),4))
dir['MM']=round(prob(ppnn,'MM',1),4)
res=prob_hacia_atras(Red6, 4, ppn,ppnn)
ppnn[0][2]=res['PM']
print(round(prob(ppnn,'PM',1),4))
dir['PM']=round(prob(ppnn,'PM',1),4)


# actualizar valores de los coeficientes
coef=prob_lateral_coef(Red6, 3,ppnn, ppn,'FM-MTI')
Red6[3][3]=copy.deepcopy(coef)
coef=prob_lateral_coef(Red6, 7,ppnn, ppn, 'MD-MP-SUad')
Red6[7][3]=copy.deepcopy(coef)
coef=prob_hacia_atras_coef(Red6, 4, ppnn,ppn)
Red6[4][3]=copy.deepcopy(coef)

df['MTI CR NM']=dir
df

df_nuevo['MTI CR NM']=dir
df_nuevo[['CR NM','MTI CR NM']]

gnb.showBN(bnf)

lista

"""Calculation of probabilities in the Bayesian network using the new method when CR = 1 (evidence) and MTI = 1, MP=1. These calculations were first performed based on the probabilities when MTI = 1 (which had already been previously calculated), and then the new evidence CR = 1 was introduced, and then the new evidence MP=1 was introduced.

A routine could have been created to automatically calculate the processing path in the network, but it was preferred to leave it in a less automated way to show all the steps. Probabilities are calculated, and, if necessary, probability factors are updated when changes occur.
"""

# Propagacion de evidencia PM al anterior
dir={}
ppn1=copy.deepcopy(ppnn)
ppnn1=copy.deepcopy(ppn1)

ppnn1[0][2]=propagacion_interna(Red6,0,'PM',1,ppn1)
print(round(prob(ppnn1,'PM',1),4))
dir['PM']=round(prob(ppnn1,'PM',1),4)
res=prob_hacia_adelante(Red6, 4, ppnn1)
ppnn1[4][2]=copy.deepcopy(res[2])
print(round(prob(ppnn1,'MM',1),4))
dir['MM']=round(prob(ppnn1,'MM',1),4)
res=prob_hacia_adelante(Red6, 7, ppnn1)
ppnn1[7][2]=copy.deepcopy(res[2])
print(round(prob(ppnn1,'CR',1),4))
dir['CR']=round(prob(ppnn1,'CR',1),4)
print(round(prob(ppnn1,'ANC',1),4))
dir['ANC']=round(prob(ppnn1,'ANC',1),4)
res=prob_lateral(Red6, 7, ppnn1, 'MM')
ppnn1[5][2]=copy.deepcopy(res['MD-MP-SUad'])
print(round(prob(ppnn1,'MD',1),4))
dir['MD']=round(prob(ppnn1,'MD',1),4)
print(round(prob(ppnn1,'MP',1),4))
dir['MP']=round(prob(ppnn1,'MP',1),4)
print(round(prob(ppnn1,'SUad',1),4))
res=prob_hacia_atras(Red6, 5, ppn1,ppnn1)
ppnn1[3][2]=res['B-F-VIH-SU']
print(round(prob(ppnn1,'B',1),4))
dir['B']=round(prob(ppnn1,'B',1),4)
print(round(prob(ppnn1,'F',1),4))
dir['F']=round(prob(ppnn1,'F',1),4)
print(round(prob(ppnn1,'VIH',1),4))
dir['VIH']=round(prob(ppnn1,'VIH',1),4)
print(round(prob(ppnn1,'SU',1),4))
dir['SU']=round(prob(ppnn1,'SU',1),4)
res=prob_hacia_atras(Red6, 3, ppn1,ppnn1)
ppnn1[1][2]=res['FM-MTI']
print(round(prob(ppnn1,'FM',1),4))
dir['FM']=round(prob(ppnn1,'FM',1),4)
print(round(prob(ppnn1,'MTI',1),4))
dir['MTI']=round(prob(ppnn1,'MTI',1),4)
ppnn1[2][2]=res['UM']
print(round(prob(ppnn1,'UM',1),4))
dir['UM']=round(prob(ppnn1,'UM',1),4)
res=prob_hacia_adelante(Red6, 6, ppnn1)
ppnn1[6][2]=copy.deepcopy(res[2])
print(round(prob(ppnn1,'FC',1),4))
dir['FC']=round(prob(ppnn1,'FC',1),4)
res=prob_hacia_adelante(Red6, 8, ppnn1)
ppnn1[8][2]=copy.deepcopy(res[2])
print(round(prob(ppnn1,'CC',1),4))
dir['CC']=round(prob(ppnn1,'CC',1),4)

df['MTI CR PM NM']=dir
df

df_nuevo['MTI CR PM NM']=dir
df_nuevo[['MTI CR NM','MTI CR PM NM']]

"""**PART SEVEN COMPARISON BETWEEN THE TWO METHODS**

The table is composed of several columns with different acronyms. These acronyms consist of two parts: the first part indicates the variables that were entered as evidence, and the last part indicates the type of method used. BN refers to the standard method employed by the PyAgrum library, and NM refers to the new method developed. It can be seen that the results are identical.
"""

df_nuevo

list=["MP BN", "MIT BN",	"CR BN",	"MTI CR BN",	"MTI CR PM BN"]
latex_code = df_nuevo[list].to_latex(index=True, float_format="%.4f")
print(latex_code)

list=["MP NM", "MIT NM",	"CR NM",	"MTI CR NM",	"MTI CR PM NM"]
latex_code = df_nuevo[list].to_latex(index=True, float_format="%.4f")
print(latex_code)

# Exportar a LaTeX
latex_code = df_nuevo.to_latex(index=True, float_format="%.4f")
print(latex_code)